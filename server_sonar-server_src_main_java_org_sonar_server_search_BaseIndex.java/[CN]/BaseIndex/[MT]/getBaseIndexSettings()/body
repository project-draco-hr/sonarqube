{
  return ImmutableSettings.builder().put("index.number_of_replicas",0).put("index.number_of_shards",1).put("index.mapper.dynamic",false).put("index.analysis.analyzer.sortable.type","custom").put("index.analysis.analyzer.sortable.tokenizer","keyword").putArray("index.analysis.analyzer.sortable.filter","trim","lowercase","truncate").put("index.analysis.analyzer.index_grams.type","custom").put("index.analysis.analyzer.index_grams.tokenizer","whitespace").putArray("index.analysis.analyzer.index_grams.filter","trim","lowercase","gram_filter").put("index.analysis.analyzer.search_grams.type","custom").put("index.analysis.analyzer.search_grams.tokenizer","whitespace").putArray("index.analysis.analyzer.search_grams.filter","trim","lowercase").put("index.analysis.analyzer.index_words.type","custom").put("index.analysis.analyzer.index_words.tokenizer","standard").putArray("index.analysis.analyzer.index_words.filter","standard","word_filter","lowercase","stop","asciifolding","porter_stem").put("index.analysis.analyzer.search_words.type","custom").put("index.analysis.analyzer.search_words.tokenizer","standard").putArray("index.analysis.analyzer.search_words.filter","standard","lowercase","stop","asciifolding","porter_stem").put("index.analysis.filter.gram_filter.type","edgeNGram").put("index.analysis.filter.gram_filter.min_gram",2).put("index.analysis.filter.gram_filter.max_gram",15).putArray("index.analysis.filter.gram_filter.token_chars","letter","digit","punctuation","symbol").put("index.analysis.filter.word_filter.type","word_delimiter").put("index.analysis.filter.word_filter.generate_word_parts",true).put("index.analysis.filter.word_filter.catenate_words",true).put("index.analysis.filter.word_filter.catenate_numbers",true).put("index.analysis.filter.word_filter.catenate_all",true).put("index.analysis.filter.word_filter.split_on_case_change",true).put("index.analysis.filter.word_filter.preserve_original",true).put("index.analysis.filter.word_filter.split_on_numerics",true).put("index.analysis.filter.word_filter.stem_english_possessive",true).put("index.analysis.analyzer.path_analyzer.type","custom").put("index.analysis.analyzer.path_analyzer.tokenizer","path_hierarchy").put("index.analysis.tokenizer.dot_tokenizer.type","pattern").put("index.analysis.tokenizer.dot_tokenizer.pattern","\\.").put("index.analysis.analyzer.uuid_analyzer.type","custom").putArray("index.analysis.analyzer.uuid_analyzer.filter","trim","lowercase").put("index.analysis.analyzer.uuid_analyzer.tokenizer","dot_tokenizer");
}
