{
  Collection<Block> originBlocks=new ArrayList<>();
  Collection<Block> duplicatedBlocks=new ArrayList<>();
  Block.Builder blockBuilder=new Block.Builder().setIndexInFile(0).setLines(30,45).setUnit(0,100);
  for (int i=0; i < 110; i++) {
    String hash=padStart("hash" + i,16,'a');
    originBlocks.add(blockBuilder.setResourceId(ORIGIN_FILE_KEY).setBlockHash(new ByteArray(hash)).build());
    duplicatedBlocks.add(blockBuilder.setResourceId("resource" + i).setBlockHash(new ByteArray(hash)).build());
  }
  underTest.computeCpd(ORIGIN_FILE,originBlocks,duplicatedBlocks);
  assertThat(duplicationRepository.getDuplications(ORIGIN_FILE)).hasSize(100);
  assertThat(logTester.logs(LoggerLevel.WARN)).containsOnly("Too many duplication groups on file " + ORIGIN_FILE_KEY + ". Keeping only the first 100 groups.");
}
